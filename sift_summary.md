
# SIFT (Scale-Invariant Feature Transform) の仕組み

## 概要
SIFTは、**画像スケール・回転に不変な特徴点**を抽出し、それを使って異なる視点や照明条件の下でも画像マッチングを可能にするアルゴリズムです。

---

## SIFTの4つの主なステップ

### 1. スケール空間極大値の検出（Scale-space extrema detection）
- ガウシアン差分（DoG: Difference of Gaussians）を使って、スケール空間上の局所的な極値（特徴点候補）を検出。
- スケール空間は、画像を段階的にぼかして（σを変化させて）構成。
- あるピクセルが、そのスケール・空間内の26近傍より明確に大きい／小さい場合、それを候補とする。

```math
D(x, y, σ) = L(x, y, kσ) - L(x, y, σ)
```
ここで L はガウス平滑化画像。

---

### 2. キーポイントの精密化（Keypoint localization）
- 特徴点候補が本当に有用な点かどうか、**コントラストが低すぎたりエッジ上の点は除外**。
- 3次元のテイラー展開を用いて特徴点の位置とスケールをサブピクセル精度で補間。

```math
\hat{x} = -\left( \frac{\partial^2 D}{\partial x^2} \right)^{-1} \frac{\partial D}{\partial x}
```

---

### 3. 向きの割り当て（Orientation assignment）
- キーポイントごとに、周辺の勾配方向をもとに**主方向**を設定。
- 勾配ヒストグラム（36分割）で主な方向を求め、80%以上のピークがあれば複数方向を割り当てる。

```math
m(x, y) = \sqrt{(L(x+1, y) - L(x-1, y))^2 + (L(x, y+1) - L(x, y-1))^2}

\theta(x, y) = \tan^{-1} \left( \frac{L(x, y+1) - L(x, y-1)}{L(x+1, y) - L(x-1, y)} \right)
```

---

### 4. 特徴量ベクトルの生成（Keypoint descriptor）
- キーポイントの周辺領域（回転・スケール正規化済み）から、**4×4の小領域に分割**し、各領域に対して**8方向の勾配ヒストグラム**を作成。
- 計 4 × 4 × 8 = **128次元の特徴ベクトル**を生成。
- 照度変化に対してロバストなように正規化＆しきい値処理。

---

## 特徴点マッチングと認識手順

### 特徴点の比較とマッチング
- 特徴ベクトル間の**ユークリッド距離**で最近傍探索。
- 2番目に近い距離との比率が小さい場合（例：0.8未満）、信頼性の高いマッチとみなす。

### 幾何学的整合性の確認（Hough変換）
- 一致した特徴点の中から、**位置・スケール・回転が一致するグループ**をHough変換でクラスタリング。
- 3点以上が一致すれば、モデル仮定として最小二乗法でアフィン変換を推定。

---

## SIFTの特徴

| 特性 | 内容 |
|------|------|
| スケール不変 | DoGによる多スケール処理 |
| 回転不変 | 勾配方向による正規化 |
| 照度変化耐性 | 微分ベース＆正規化処理 |
| 部分的アフィン不変 | 記述子がロバストに構成 |
| 高い識別性 | 128次元で誤マッチを低減 |
| 実時間性 | 特徴点は効率的に抽出可能 |

---

## 応用例
- 物体認識（例：部分的に隠れた対象の検出）
- ロボットの自己位置推定
- パノラマ画像の生成
- 3D再構成、画像トラッキング

---

## 結論
SIFTは高いロバスト性と識別性を持ち、多様な視点・照明・部分的な遮蔽下でも安定した画像マッチング・認識を可能にします。
